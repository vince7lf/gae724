\noindent Dans le cadre du projet pour \acrshort{pjcci}, une plateforme technologique sera mise à la disposition des gestionnaires du pont afin de les aider à prendre les décisions les plus responsables et raisonnables possibles. Mais la mise en opération d'une solution innovante et fiable, qui concilie des algorithmes d'apprentissage profond, du temps réel, des nano ordinateurs, et des conditions climatiques variables, est complexe. Dans une certaine mesure, l'essai va contribuer à la recherche de solutions afin de répondre au défi pour le domaine du transport actif et durable d'être soutenu par des solutions technologiques fiables (opérationnelles), l'objectif étant de pouvoir offrir des services de qualité et sécuritaires sur l'ensemble des quatre saisons.
\vspace{\baselineskip}
\\
\noindent La seconde problématique que l'essai va contribuer à résoudre concerne les limites d'un nano ordinateur. L'inférence nécessite une architecture et une puissance machine différente de celle nécessaire pour l'entrainement. Les architectures de réseaux de neurones sont adaptées et optimisées pour l'inférence. L'essai va permettre de préciser les capacités du nano ordinateur pour l'inférence de diverses architectures de réseaux de neurones pleinement connectés ("\acrshort{fcn}" en anglais) et la segmentation sémantique en temps réel avec des vidéos de différentes propriétés (résolutions et nombre d'images pas seconde). Il existe des tests encourageants \parencite{nvidia_jetson_2019-1, nguyen_mavnet_2019,zheng_real-time_2020}, qui sont utilisés comme base de travail et référence, même si ceux-ci sont limités à des types d'application qui ne sont pas les mêmes que pour l'essai.
\vspace{\baselineskip}
\\
\noindent Il est difficile de trouver des jeux de données pour entrainer les réseaux de neurones pleinement connectés (\acrshort{fcn}) adaptés à la problématique. La technique de "Data augmentation" permet de démarrer d'une architecture qui a déjà appris avec un jeu d'images important (milliers d'images), et de lui faire apprendre davantage, en lui fournissant un plus petit jeu d'images (centaines d'images) de la nouvelle zone d'étude. Par exemple une architecture peut avoir appris à classifier des images de la Californie, États-Unis. Pour lui permettre de classifier des images de la Ville de Sherbrooke, il est souhaitable de lui fournir un nouveau jeu de données spécifique à cette ville afin qu'il s'adapte (ses paramètres) à cette région. Dans le contexte de cet essai, les données acquises sur le terrain sont fournies aux différents modèles qui sont évalués, et les architectures sont ré entrainées avec ce nouveau jeu d'images adapté à la zone d'étude.
\vspace{\baselineskip}
\\
\noindent La paramétrisation (des "hyper paramètres") des réseaux de neurones est "subtile" et "intuitive" et requière de l'expérience. C'est un processus d'essais-erreurs qui est couteux en temps, et risqué puisqu'il n'y a aucune garantie de succès. La technique d'apprentissage par transfert ("Transfer Learning" en anglais) permet d'hériter d'une architecture qui est déjà entrainée et configurée, et de l'adapter pour répondre à ses besoins. Cette technique permet un gain en temps et en énergie (et en argent) important puisque le temps de conception (architecture et configuration) et le temps d'entrainement, de validation et de tests sont diminués de façon non négligeable.
\begin{comment}
Par exemple l'architecture "VGG" prend 2-3 semaines d'entrainement \parencite{simonyan_very_2015} avec 4 \acrshort{gpu} Titan Black (NVIDIA), coutant 1,200 \$US (Amazon.com) chacun (pour un total de 4,800\$US, et cela juste pour les \acrshort{gpu}s, qui ne sont qu'un des éléments de l'infrastructure nécessaire). Étant donné que de multiples tentatives sont nécessaires (cycles essai-erreur), la stratégie est d'entrainer plusieurs modèles en parallèle afin d'accélérer le développement, ce qui implique un coût élevé en infrastructure.
\end{comment}
La problématique pour l'essai est de trouver l'architecture qui est la plus adaptée pour répondre au besoin, et il en existe des milliers \parencite{koh_model_2018}. La recherche dans la littérature permet heureusement de limiter les choix et donner des pistes \parencite{zheng_real-time_2020, nguyen_mavnet_2019, nvidia_jetson_2019-1}. La problématique de la conception existe toujours, car l'architecture a besoin d'être étudiée, adaptée et ré entrainée, jusqu'à l'obtention de résultats probants. Mais la paramétrisation des hyper paramètres n'est plus nécessaire (supposément), ce qui est avantageux.
\vspace{\baselineskip}
\\
\noindent Même si les tests du modèle donnent des résultats satisfaisants en théorie, la réalité du terrain peut surprendre. Le test du modèle doit se faire dans des conditions réelles avec de nouvelles données (images), celles qui sont captées par le système hôte sur le terrain d'implantation: dans le jargon de l'intelligence artificielle, c'est l'"inférence" \parencite{copel_whats_2016, nvidia_jetson_2019-1}. Il est assez probable que l'architecture doive retourner à une phase de ré entrainement. De plus, le système hôte, dans notre cas le nano ordinateur NVIDIA Jetson Nano, est conçu avec une architecture matérielle limitée (\acrshort{gpu}, \acrshort{cpu}s, mémoire, taux de transfert, alimentation) et verra, au besoin, son architecture matérielle adaptée et remise en question.