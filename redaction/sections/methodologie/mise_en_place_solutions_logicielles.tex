\myparagraph{Jetson Nano}
\par Le nano ordinateur est destiné a l'inférence. NVIDIA fournit tout un système d'installation, qui est nommé JetPack, et qui contient un système d'exploitation basée sur Ubuntu, Linux For Tegra L4T), le cadre applicatif ('framework') et les librairies nécessaires pour l'inférence, tel que Python, pytorch, les modèles pré-entrainés au format ONNX, le compilateur CUDA, et le SDK TensorRT.
\myparagraph{Compute Canada}
\par Le nano ordinateur est destiné a l'inférence, et non l'entrainement de modèles. Il n'est pas non plus destiné a être un environnement de développement. Un autre environnement de travail est donc nécessaire pour développer, et doit posséder les capacités matérielles (GPUs, mémoires, espace de stockage) et logicielles (librairies) pour entrainer un modèle. Heureusement mon directeur de projet m'a introduit à Compute Canada, ou Calcul Québec. Compute Canada fournit un espace de travail puissant aux chercheurs et aux universitaires. Il n'est pas évident de posséder à la maison un environnement permettant de faire de l'apprentissage profond. Ce que je ne pouvais faire avec le nano ordinateur, j'ai pu le faire dans l'environnement de Compute Canada, tel que compiler un fork de torchvision, réentrainer des modèles, générer des onnx. Avoir accès a cet environnement de travail a été un élément déterminant dans le cadre de cet essai.
\mysubparagraph{Compte Compute Canada}
\par Compute Canada mets à disposition des ressources matérielles puissantes et l'accès a des libraires de haute technologie telle que pour l'apprentissage profond, permettant d'avoir un environnement de travail professionnel et performant rapidement. Les ressources matérielles à disposition sont des grappes de serveurs, de CPUs et GPUs de différents types, ainsi que de l'espace de stockage. Les librairies sont disponibles via un repository privé, et lorsque certaines étaient manquantes (onnx et onnxruntime), j'ai fait une demande par courriel. L'administrateur a pu rendre disponible l'une des deux (onnx), la seconde (onnxruntime) étant beaucoup plus complexe a installé, pour l'avoir tenté sur le nano ordinateur. 
\par L'autre avantage de l'environnement de Compute Canada est la mise à disposition de Jupyter Notebook, afin de tester rapidement du code Python. Par contre il n'est pas conseillé d'exécuter du code nécessitant des délais, tels que l'entrainement d'un modèle. 
\par L'un des irritants est de ne pas pouvoir exécuter un container docker tel quel. Il faut le convertir au format Singularity. Dans le cadre du projet cela m'aurait facilité la tâche, car NVIDIA fournit des docker prêt à l'utilisation pour le réentrainement. Je n'ai malheureusement pas pris le temps et la chance de convertir un container docker au format Singularity. Je ne sais pas si c'est une activité assez simple ou complexe, mais du peu que j'ai lu cela semble assez "rapide".
\mysubparagraph{Jupyter Notebook}
\par Le besoin de tester du code Python est toujours nécessaire. La console Python n'étant vraiment pas conviviale, un environnement Jupyter Notebook est un compromis incontournable. Heureusement Compute Canada fournit un accès à des notebooks depuis Internet, permettant en plus d'hériter de leur environnement de travail. Il est à noter que les notebooks n'ont pas été utilisés pour entrainer un modèle ou générer des onnx, mais de tester du code Python simple, comme visualiser des images, transformer des tensors, et évaluer la segmentation prédite générée avec le vérité terrain (\acrshort{gt}). 
\paragraph{NVIDIA}
\mysubparagraph{Compte NVIDIA}
\par NVIDIA mets à disposition tout un écosystème éducatif permettant aux développeurs et aux chercheurs d'obtenir de l'aide au sujet de leur produit et librairies. Dans le cadre de l'essai, un compte NVIDIA a été créé, permettant d'accéder au forum de développeurs, et les containers  docker par exemple. Il est aussi possible d'accéder à du matériel éducatif grâce à l'institut DeepLearning de NVIDIA, dont l'accès a été commandité par mon directeur de projet. Le forum de développeurs a été un outil très utile dans le cadre de ce projet, car le dépôt d'une question m'a permis de me débloquer. Je n'étais pas capable de re générer l'ONNX à partir du code source et de la documentation fournie par NVIDIA pour un modèle FCN. Le développeur principal de l'application a répondu et m'a guidé dans la résolution du problème. Les autres ressources ont eu un impacte limité dans le cadre de ce projet, puisque par exemple le container docker et DIGITS n'ont pas pu être utilisé. Le code source des modèles est disponible sans nécessiter de compte, de même que les SDKs Jetpack.
\mysubparagraph{NVIDIA DIGITS}
\par NVIDIA fournit aux développeurs un environnement visuel permettant de réentrainer les modèles FCN qu'ils fournissent avec leurs propres dataset. Cet environnement se nomme DIGITS. Malheureusement il est nécessaire d'avoir son propre matériel, le système d'exploitation Ubuntu 18.04 LTS, et très recommandé d'avoir au moins un GPU et un ordinateur performant. Ce qui n'est malheureusement pas mon cas. DIGITS ne s'installe pas sur le nano ordinateur, ni sous Windows, ni même un Ubuntu sous windows (WSL). Cette option a donc été abandonnée rapidement. 
\mysubparagraph{Docker NVIDIA}
\par NVIDIA fournit aux développeurs des containers docker, avec tout ce qui est nécessaire pour réentrainer un modèle et re générer un ONNX, par exemple. Malheureusement la capacité du nano ordinateur ne permet pas de travailler efficacement avec un container docker, le nano ordinateur devient sans réponse, nécessitant un redémarrage forcé ("hard-reboot"). Cette option a donc été aussi abandonnée rapidement. 
\mysubparagraph{NVIDIA DeepStream}
\par Durant le déroulement de l'essai, NVIDIA a mis à disposition un environnement d'apprentissage profond, nommé "DeepStream", facilitant la conception et la génération de modèles, jusqu'à l'inférence. Cet outil n'a pas été évalué, mais pourrait être un outil alternatif pour réentrainer un modèle.