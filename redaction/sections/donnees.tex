\myparagraph{Données}\label{metho:data}
\par Les ressources mises à disposition par le constructeur du Jetson Nano, NVIDIA, font référence à des jeux de données qui sont disponibles publiquement.
\par En complément des ressources de NVIDIA, deux références scientifiques seront principalement étudiées, car leurs recherches ont été faites avec le Jetson Nano (\cite{nguyen_mavnet_2019} et \cite{chong_real-time_1992}). Beaucoup de références ont été publiées ces deux dernières années sur le sujet de la segmentation sémantique, ils existent donc de multiples alternatives inspirantes.
\par Internet est une mine de données : il existe des forums et des blogues dans lesquels des utilisateurs publient leurs expérimentations de la segmentation sémantique en temps réel avec le Jetson Nano (\cite{dustin_realtime_2019}), ou plus génériquement la segmentation sémantique; des sites comme "modelzoo.co" ou "kaggle.com" sont des entrepôts de données et de modèles \acrshort{fcn} prêts à être utilisés; une autre option a été d'effectuer une recherche d'images ou de vidéos de la piste multifonctionnelle du pont Jacques-Cartier via les sites de recherche tels que Google. 
\par L'\acrlong{apcpontjc} existe depuis de nombreuses années pour promouvoir le transport actif et conserver la piste multifonctionnelle du pont Jacques Cartier ouverte durant l'hiver. Ils fournissent, via leurs sites Internet, des collections de vidéos et d'images qui seront utilisées après leur avoir demandé leur autorisation verbale et écrite. \cite{association_des_pietons_et_cyclistes_du_pont_jacques-cartier_pontjacques-cartier365com_2020} \cite{association_des_pietons_et_cyclistes_pont_jacques-cartier_flickr_2020}
\myparagraph{Approche prévue pour le traitement des données}
\par Il y a deux phases à cet essai: l'inférence avec des modèles déjà prêts et l'inférence avec des modèles ré entrainés. Les données utilisées par l'inférence sont des vidéos (d'une certaine résolution et d'un certain nombre d'images pas seconde), et celles pour l'entrainement sont des images. Dans les deux cas, les images pour l'entrainement ou l'inférence doivent être d'une taille bien précise, celles avec lesquelles le modèle a été, ou sera, entrainées. La résolution et la qualité de l'image vidéo seront nivelées vers le bas afin de déterminer la limite inférieure acceptable pour la détection la plus efficace et fiable possible. La résolution et le nombre d'images par seconde de la vidéo sont contrôlés par le logiciel ("driver" en anglais) de la caméra, et sont configurables. 
\par Tout cela signifie que les vidéos ou nouvelles images devront être traités pour répondre à une certaine taille et résolution requise par le modèle, tout en conservant une qualité élevée (nombre de pixels, niveaux de couleurs). De nouvelles images pour l'entrainement seront extraites des vidéos, et annotées. 
\par Certains cadres d'application logicielle ("framework") d'apprentissage profond (par exemple "Keras") offrent l'option d'augmenter automatiquement le jeu de données avec des techniques d'augmentation de données (par exemple la rotation, le redimensionnement, l'effet miroir), ce qui est très utile et non négligeable.
\par Voici le tableau de synthèse des données qui ont été découvertes et qui seront potentiellement utilisées dans le cadre de l'essai, incluant la référence à l'architecture du modèle d'apprentissage profond.
{
   \clearpage 
   \newpage
   % \begin{landscape}
   \newcounter{magicrownumbers}
   \newcommand\rownumber{\stepcounter{magicrownumbers}\arabic{magicrownumbers}}
   \vspace{0.1em} % Adjust the height of the space between caption and tabular
   \begin{longtable}[t]{@{}p{1em}|p{35em}} % p{10em}p{25em} with landscape
      \caption{Tableau des données}\label{tab:datasets}\\
      & \textbf{Spécification} \\
      \hline
      \endfirsthead
      & \textbf{Spécification} \\
      \hline
      \endhead
      \endfoot
      \endlastfoot
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Réseau: SegNet\\Jeu de données: CamVid\\Vidéo: 10 minutes\\Résolution/s: HD\\
         \hline
         SegNet est un réseau qui a été créé pour la segmentation sémantique de vidéos. Il a été entrainé avec le jeu de données de CamVid, qui procurent des vidéos de la route avec la même perspective que le conducteur du véhicule. Un modèle entrainé est disponible pour le Jetson Nano.\\
         \url{https://github.com/PengKiKi/camvid}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Réseau: MFANet\\Jeu de données: Cityscapes\\Nombre d'images: 5000\\Résolutions: 1280x1024\\
         \hline
         MFANet est un réseau qui a été créé en 2019 pour la segmentation sémantique sur des appareils tel que le Jetson Nano. Il a été entrainé avec le jeu de données de Cityscapes, qui procurent des images de scènes urbaines. Différentes stratégies d'augmentation de données sont utilisées. Des tests ont été faits avec le Jetson Nano.\\
         leejy@ustb.edu.cn\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Réseau: RESNet18\\Jeu de données: Cityscapes\\Nombre d'images: 25 000\\Résolutions: 360x720, 512x256, 1024x512, 2048x1024\\
         \hline
         Cityscapes est un jeu de données qui fournit des images de rues spécifiquement destinées pour la segmentation sémantique. Il peut être utilisé par de nombreux réseaux. RESNet18 a été entrainé avec ce jeu et est disponible en diverses résolutions pour le Jetson Nano.\\
         \url{https://github.com/tynguyen/MAVNet/tree/master/data/perch_drone}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Réseau: RESNet18\\Jeu de données: DeepScenes\\Nombre d'images: 15 000\\Résolutions: 576x320, 864x480 \\
         \hline
         DeepScene propose un modèle et un jeu de données. Le modèle est entrainé avec différents jeux de données, comme Cityscpapes, SUN-RGBD, Synthia. Le jeu de données fournit des images de forêt, qui est destinée pour la segmentation sémantique. RESNet18 a été entrainé avec ce jeu et est disponible en deux  résolutions pour le Jetson Nano.\\
         \url{http://deepscene.cs.uni-freiburg.de}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Réseau: RESNet18\\Jeu de données: Synthia\\Nombre d'images: 220 000\\Résolutions: 1280x760\\
         \hline
         Le jeu de données Synthia fournit des images (et vidéos) de scènes de rue comme celui de Cityscapes, et qui est destiné pour la segmentation sémantique. RESNet18 a été entrainé avec ce jeu. Il n'a pas été testé avec le Jetson Nano.\\
         \url{http://3dvision.princeton.edu/datasets.html}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Jeu de données: Association des piétons et cyclistes pont Jacques-Cartier\\Nombre d'images: 313\\Résolutions: variées\\
         \hline
         L'\acrlong{apcpontjc} a une collection d'images et de vidéos de la piste multifonctionnelle du pont Jacques-Cartier. Ce n'est pas un jeu de données qui est prêt à être utilisé pour l'apprentissage tel quel, il doit être préparé. Mais c'est une source de données qui est très importante pour l'essai. Il est envisagé de contacter l'association au besoin afin de leur demander leur collaboration pour la collecte d'autres d'images ou vidéos.\\
         \url{https://www.flickr.com/photos/pontjacquescartier}\\
         \url{http://pontjacquescartier365.com/videos-pont-jacques-cartier}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Jeu de données: images et vidéo sur Internet\\Nombre d'images: entre 30-50\\Résolutions: variées\\
         \hline
         Internet est une source de données non négligeable en termes de données. Quelques images et vidéos de la piste multifonctionnelle du pont Jacques-Cartier, autre que celles fournies par L'\acrlong{apcpontjc}, sont disponibles. Ce n'est pas un jeu de données qui est prêt à être utilisé pour l'apprentissage tel quel, il doit être préparé. Mais c'est une source de données qui est très importante pour l'essai.\\
         \url{https://google.ca}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Jeux de données: KITI Road/Lane Detection\\
         \hline
         Ce jeu de données contient 289 images d'entrainement et 290 images de tests d'image de routes urbaines. Il existe une grande multitude de modèles qui sont entrainés avec ce jeu de données.\\
         \url{http://www.cvlibs.net/datasets/kitti/eval_road.php}\\
      \end{tabular}\\
      \hline
      \rownumber & \begin{tabular}[t]{@{}p{35em}@{}}
         Jeux de données: Personnel\\Nombre d'images et vidéos: 188 images de 1080x1920; 19 vidéos de 30-60 secondes de 1080x1920 et 60\acrshort{fps}.\\
         \hline
         Ce jeu de données contient des vidéos de différentes sections de pistes cyclables de mon quartier. Les vidéos ont été prises au mois de mars, dans des conditions ensoleillées, mais avec des endroits de la piste ombragée, sèche ou mouillée, bordée d'herbe ou de neige, parfois avec des passants. 188 images ont été extraites des vidéos.\\
      \end{tabular}\\
      \hline
   \end{longtable}
   % \end{landscape}
   % \clearpage
   % \newpage
}